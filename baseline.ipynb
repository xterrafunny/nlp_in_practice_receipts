{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e740225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from seqeval.metrics.sequence_labeling import get_entities\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be248c7",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45c869f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_bio_tagging(row):\n",
    "    tokens = row[\"tokens\"]\n",
    "    good = row[\"good\"].split(',')[0].split()\n",
    "    brand = row[\"brand\"].split(',')[0].split()\n",
    "    tags = ['O'] * len(tokens)\n",
    "    for i, token in enumerate(tokens):\n",
    "        if len(good) > 0 and tokens[i:i + len(good)] == good:\n",
    "            tags[i] = \"B-GOOD\"\n",
    "            for j in range(i + 1, i + len(good)):\n",
    "                tags[j] = \"I-GOOD\"\n",
    "        if len(brand) > 0 and tokens[i:i + len(brand)] == brand:\n",
    "            tags[i] = \"B-BRAND\"\n",
    "            for j in range(i + 1, i + len(brand)):\n",
    "                tags[j] = \"I-BRAND\"\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b873cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_tag = [\"O\", \"B-GOOD\", \"I-GOOD\", \"B-BRAND\", \"I-BRAND\", \"PAD\"]\n",
    "tag_to_index = {tag: index for index, tag in enumerate(index_to_tag)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a8c3d",
   "metadata": {},
   "source": [
    "# Prepare datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58c5aaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceiptsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, fasttext):\n",
    "        super().__init__()\n",
    "        self.is_predict = \"tags\" not in df.columns\n",
    "        self.data = df[[\"tokens\", \"good\", \"brand\", \"tags\"]] if not self.is_predict else df[[\"tokens\", \"id\"]]\n",
    "        self.data = self.data.values\n",
    "        self.fasttext = fasttext\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        identifier = 0 if not self.is_predict else self.data[index][1]\n",
    "        tokens = self.data[index][0]\n",
    "        embeddings = self.fasttext.wv[tokens]\n",
    "        goods = self.data[index][1].split(',') if not self.is_predict else list()\n",
    "        brands = self.data[index][2].split(',') if not self.is_predict else list()\n",
    "        tags = self.data[index][3] if not self.is_predict else [\"O\"] * len(tokens)\n",
    "        target = [tag_to_index[tag] for tag in tags]\n",
    "        return identifier, tokens, embeddings, goods, brands, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847269bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    ids, tokens_sequence, embeddings_sequence, goods, brands, targets = list(zip(*batch))\n",
    "    embeddings_sequence = pad_sequence([torch.FloatTensor(sequence) for sequence in embeddings_sequence], batch_first=True)\n",
    "    targets = pad_sequence([torch.LongTensor(target) for target in targets], batch_first=True, padding_value=tag_to_index[\"PAD\"])\n",
    "    return ids, tokens_sequence, embeddings_sequence, goods, brands, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6ab59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceiptsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self,\n",
    "                 train_dataset_path,\n",
    "                 test_dataset_path,\n",
    "                 fasttext_path,\n",
    "                 val_split_size,\n",
    "                 batch_size,\n",
    "                 num_workers):\n",
    "        super().__init__()\n",
    "        self.train_dataset_path = train_dataset_path\n",
    "        self.test_dataset_path = test_dataset_path\n",
    "        self.fasttext_path = fasttext_path\n",
    "        self.val_split_size = val_split_size\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        self.fasttext = FastText.load(self.fasttext_path)\n",
    "        self.train_df = pd.read_csv(self.train_dataset_path).fillna(\"\")\n",
    "        self.test_df = pd.read_csv(self.test_dataset_path)\n",
    "        \n",
    "        self.train_df[\"tokens\"] = self.train_df[\"name\"].str.lower().str.split()\n",
    "        self.test_df[\"tokens\"] = self.test_df[\"name\"].str.lower().str.split()\n",
    "        \n",
    "        self.train_df[\"tags\"] = self.train_df.apply(apply_bio_tagging, axis=1)\n",
    "    \n",
    "    def setup(self, stage: str):\n",
    "        self.train_df, self.val_df = train_test_split(self.train_df, test_size=self.val_split_size)\n",
    "        \n",
    "        self.train_dataset = ReceiptsDataset(self.train_df, self.fasttext)\n",
    "        self.val_dataset = ReceiptsDataset(self.val_df, self.fasttext)\n",
    "        self.predict_dataset = ReceiptsDataset(self.test_df, self.fasttext)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.train_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.val_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(self.predict_dataset,\n",
    "                                           batch_size=self.batch_size,\n",
    "                                           num_workers=self.num_workers,\n",
    "                                           collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c3aac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATASET_PATH = \"train_dataset.csv\"\n",
    "TEST_DATASET_PATH = \"test_dataset.csv\"\n",
    "FASTTEXT_PATH = \"fasttext.model\"\n",
    "VAL_SPLIT_SIZE = 0.1\n",
    "BATCH_SIZE = 512\n",
    "NUM_WORKERS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c641742",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = ReceiptsDataModule(\n",
    "    TRAIN_DATASET_PATH,\n",
    "    TEST_DATASET_PATH,\n",
    "    FASTTEXT_PATH,\n",
    "    VAL_SPLIT_SIZE,\n",
    "    BATCH_SIZE,\n",
    "    NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09717716",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7db73afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Score:\n",
    "    def __init__(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def update(self, pred, target):\n",
    "        pred = frozenset(x for x in pred)\n",
    "        target = frozenset(x for x in target)\n",
    "        self.tp += len(pred & target)\n",
    "        self.fp += len(pred - target)\n",
    "        self.fn += len(target - pred)\n",
    "\n",
    "    def reset(self):\n",
    "        self.tp = 0\n",
    "        self.fp = 0\n",
    "        self.fn = 0\n",
    "\n",
    "    def get(self):\n",
    "        if self.tp == 0:\n",
    "            return 0.0\n",
    "        precision = self.tp / (self.tp + self.fp)\n",
    "        recall = self.tp / (self.tp + self.fn)\n",
    "        return 2 / (1 / precision + 1 / recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "469a277a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReceiptsModule(pl.LightningModule):\n",
    "    def __init__(self,\n",
    "                 rnn_input_size,\n",
    "                 rnn_hidden_size,\n",
    "                 rnn_num_layers,\n",
    "                 rnn_dropout,\n",
    "                 mlp_hidden_size,\n",
    "                 learning_rate):\n",
    "        super().__init__()\n",
    "        self.learning_rate = learning_rate\n",
    "        self.lstm = nn.RNN(input_size=rnn_input_size,\n",
    "                           hidden_size=rnn_hidden_size,\n",
    "                           num_layers=rnn_num_layers,\n",
    "                           batch_first=True,\n",
    "                           dropout=rnn_dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(rnn_hidden_size, mlp_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(mlp_hidden_size, len(index_to_tag))\n",
    "        )\n",
    "        self.criterion = nn.CrossEntropyLoss(ignore_index=tag_to_index[\"PAD\"], reduction=\"mean\")\n",
    "        self.f1_good_train = F1Score()\n",
    "        self.f1_brand_train = F1Score()\n",
    "        self.f1_good_val = F1Score()\n",
    "        self.f1_brand_val = F1Score()\n",
    "    \n",
    "    def forward(self, sequences):\n",
    "        sequences, _ = self.lstm(sequences)\n",
    "        logits = self.mlp(sequences)\n",
    "        return logits\n",
    "    \n",
    "    def training_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_train.update(goods_pred, goods[i])\n",
    "            self.f1_brand_train.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/train\", loss, on_epoch=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_train\", self.f1_good_train.get())\n",
    "        self.log(\"metric/f1_brand_train\", self.f1_brand_train.get())\n",
    "        self.f1_good_train.reset()\n",
    "        self.f1_brand_train.reset()\n",
    "        \n",
    "\n",
    "    def validation_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, goods, brands, targets = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        loss = self.criterion(logits.transpose(1, 2), targets)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"]\n",
    "            brands_pred = [' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"]\n",
    "            self.f1_good_val.update(goods_pred, goods[i])\n",
    "            self.f1_brand_val.update(brands_pred, brands[i])\n",
    "        self.log(\"loss/val\", loss)\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"metric/f1_good_val\", self.f1_good_val.get())\n",
    "        self.log(\"metric/f1_brand_val\", self.f1_brand_val.get())\n",
    "        self.f1_good_val.reset()\n",
    "        self.f1_brand_val.reset()\n",
    "    \n",
    "    def predict_step(self, batch, _):\n",
    "        ids, tokens_sequence, embeddings_sequence, _, _, _ = batch\n",
    "        logits = self(embeddings_sequence)\n",
    "        tags_indices_sequence = torch.argmax(logits, dim=-1).detach().cpu().numpy().tolist()\n",
    "        result = list()\n",
    "        for i, tags_indices in enumerate(tags_indices_sequence):\n",
    "            tags = [index_to_tag[index] for index in tags_indices[:len(tokens_sequence[i])]]\n",
    "            entities = get_entities(tags)\n",
    "            goods_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"GOOD\"])\n",
    "            brands_pred = ','.join([' '.join(tokens_sequence[i][start:finish + 1]) for t, start, finish in entities if t == \"BRAND\"])\n",
    "            result.append([ids[i], goods_pred, brands_pred])\n",
    "        return result\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), self.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c6e6593",
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN_INPUT_SIZE = 300\n",
    "RNN_HIDDEN_SIZE = 300\n",
    "RNN_NUM_LAYERS = 3\n",
    "RNN_DROPOUT = 0.1\n",
    "MLP_HIDDEN_SIZE = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "model = ReceiptsModule(\n",
    "    RNN_INPUT_SIZE,\n",
    "    RNN_HIDDEN_SIZE,\n",
    "    RNN_NUM_LAYERS,\n",
    "    RNN_DROPOUT,\n",
    "    MLP_HIDDEN_SIZE,\n",
    "    LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62395114",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = pl.loggers.TensorBoardLogger(\"tb_logs\", name=\"ner_rnn_baseline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87bbedf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    devices=[0],\n",
    "    logger=logger,\n",
    "    max_epochs=30,\n",
    "    log_every_n_steps=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "855166b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: tb_logs/ner_rnn_baseline\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | lstm      | RNN              | 541 K \n",
      "1 | mlp       | Sequential       | 153 K \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "695 K     Trainable params\n",
      "0         Non-trainable params\n",
      "695 K     Total params\n",
      "2.781     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xterrafunny/anaconda3/envs/nlp_in_practice/lib/python3.10/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: PAD seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/xterrafunny/anaconda3/envs/nlp_in_practice/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 512. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694d1ba6af1d41c7abde4b62d674f0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xterrafunny/anaconda3/envs/nlp_in_practice/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 484. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xterrafunny/anaconda3/envs/nlp_in_practice/lib/python3.10/site-packages/pytorch_lightning/utilities/data.py:76: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 452. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ac2a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09e4e1aa74a41d9b3b0603252eb3d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.predict(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f54e3b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>good</th>\n",
       "      <th>brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>торт</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>смеситель</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>лимон</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>коньяк</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>рамка</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>наконечники</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>шоколад</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>опора</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id         good brand\n",
       "0        0                   \n",
       "1        1         торт      \n",
       "2        2    смеситель      \n",
       "3        3        лимон      \n",
       "4        4       коньяк      \n",
       "...    ...          ...   ...\n",
       "4995  4995        рамка      \n",
       "4996  4996                   \n",
       "4997  4997  наконечники      \n",
       "4998  4998      шоколад      \n",
       "4999  4999        опора      \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame(sum(pred, list()), columns=[\"id\", \"good\", \"brand\"])\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d054b57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"submission_baseline.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
